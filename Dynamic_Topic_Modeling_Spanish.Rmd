
---
title: "Dynamic Topic Modeling on Spanish Newspaper Articles"
author: "Adapted from Bernadeta Griciūtė"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(topicmodels)
library(ldatuning)
library(LDAvis)
library(tidytext)
library(dplyr)
library(ggplot2)
library(lubridate)
```

## Introduction

This R Markdown file implements dynamic topic modeling on Spanish newspaper articles using a CSV file. The file contains columns: `date`, `source`, and `content`.

## Data Preparation

```{r data-preparation}
# Load CSV data
file_path <- "./articles.csv"  # Update with your CSV file path
data <- read.csv(file_path, stringsAsFactors = FALSE)

data <- data %>%
  mutate(date = mdy(date) #,
         # year = year(date),
         # month = month(date),
         # day = day(date)
         )

head(data)
```

## Text Preprocessing

```{r text-preprocessing}
# Create a corpus
corpus <- Corpus(VectorSource(data$processed_text))

# # Convert to lowercase
# corpus <- tm_map(corpus, content_transformer(tolower))
# 
# # Remove punctuation, numbers, and stopwords
# corpus <- tm_map(corpus, removePunctuation)
# corpus <- tm_map(corpus, removeNumbers)
# corpus <- tm_map(corpus, removeWords, stopwords("spanish"))
# 
# # Stem the text (optional)
# library(SnowballC)
# corpus <- tm_map(corpus, stemDocument, language = "spanish")

# Convert to plain text
#corpus <- tm_map(corpus, PlainTextDocument)
```

## Tokenization and Term-Document Matrix

```{r tdm-creation}
# Create a Document-Term Matrix (DTM)
dtm <- DocumentTermMatrix(corpus)

# Remove sparse terms to optimize computation
dtm <- removeSparseTerms(dtm, 0.99)

# Summary of the DTM
dim(dtm)
```

## Topic Modeling

```{r lda-model}
# Optimal number of topics
result <- FindTopicsNumber(
  dtm,
  topics = seq(from = 2, to = 16, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 1234),
  mc.cores = 2L,
  verbose = TRUE
)

FindTopicsNumber_plot(result)

```

```{r}

# Fit LDA Model
optimal_topics <- 5  # Update based on results
lda_model <- LDA(dtm, k = optimal_topics, control = list(seed = 1234))

```

```{r}

# Get terms and topics
terms(lda_model, 10)
topics(lda_model)
```

## Visualization

```{r visualization}
# Prepare LDAvis data
library(LDAvis)
library(servr)

json <- createJSON(
  phi = posterior(lda_model)$terms,
  theta = posterior(lda_model)$topics,
  doc.length = rowSums(as.matrix(dtm)),
  vocab = colnames(as.matrix(dtm)),
  term.frequency = colSums(as.matrix(dtm))
)

serVis(json, open.browser = TRUE)
```

## Dynamic Topic Modeling (Future Steps)

Incorporate dynamic topic modeling packages or manual partitioning of the data based on `date` to implement a time-series analysis.

---

## Dynamic Topic Modeling

To perform dynamic topic modeling (DTM) using the temporal information in the dataset, follow these steps:

### 1. Data Partitioning

Split the data into subsets based on a time window (e.g., by month or quarter).

```{r data-partitioning}
# Create a time-based grouping (monthly in this example)
data$month <- floor_date(data$date, "month")

# Group the content by month
grouped_data <- data %>%
  group_by(month) %>%
  summarise(content = paste(content, collapse = " "))
```

### 2. Generate Time-Sliced Corpora

Create a Document-Term Matrix (DTM) for each time period.

```{r time-sliced-dtm}
# Initialize an empty list to store DTMs
dtm_list <- list()

# Loop through each time period
for (i in 1:nrow(grouped_data)) {
  corpus_time <- Corpus(VectorSource(grouped_data$content[i]))
  corpus_time <- tm_map(corpus_time, content_transformer(tolower))
  corpus_time <- tm_map(corpus_time, removePunctuation)
  corpus_time <- tm_map(corpus_time, removeNumbers)
  corpus_time <- tm_map(corpus_time, removeWords, stopwords("spanish"))
  dtm_time <- DocumentTermMatrix(corpus_time)
  dtm_time <- removeSparseTerms(dtm_time, 0.99)
  dtm_list[[i]] <- dtm_time
}

# Verify the structure
str(dtm_list)
```

### 3. Apply Dynamic Topic Modeling

Use packages like `ldaseq` or external tools for dynamic topic modeling. For example, using the `topicmodels` package:

```{r dtm-analysis}
# Analyze changes in topics over time (manual partition example)
lda_models <- lapply(dtm_list, function(dtm) {
  LDA(dtm, k = optimal_topics, control = list(seed = 1234))
})

# Example: Extract and compare topics for the first two time periods
terms(lda_models[[1]], 10)
terms(lda_models[[2]], 10)
```

### 4. Visualization and Insights

Visualize the evolution of topics over time.

```{r visualize-evolution}
# Example visualization of topic proportions over time
topic_proportions <- lapply(lda_models, function(model) {
  posterior(model)$topics
})

# Combine results into a data frame for visualization
proportions_df <- do.call(rbind, lapply(1:length(topic_proportions), function(i) {
  data.frame(
    Time = grouped_data$month[i],
    Topic = colnames(topic_proportions[[i]]),
    Proportion = rowMeans(topic_proportions[[i]])
  )
}))

ggplot(proportions_df, aes(x = Time, y = Proportion, color = Topic)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Topic Proportions Over Time", x = "Time", y = "Proportion")
```

